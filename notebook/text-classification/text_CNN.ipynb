{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there a GPU available: \n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Is there a GPU available: \"),\n",
    "print(tf.config.experimental.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load text into datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/rt-polaritydata/rt-polarity-pos.txt\n",
      "./data/rt-polaritydata/rt-polarity-neg.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<MapDataset shapes: ((), ()), types: (tf.string, tf.int64)>,\n",
       " <MapDataset shapes: ((), ()), types: (tf.string, tf.int64)>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "\n",
    "base_path = './data'\n",
    "raw_data_path = 'rt-polaritydata'\n",
    "\n",
    "parent_dir = os.path.join(base_path, raw_data_path)\n",
    "FILE_NAMES = ['rt-polarity-pos.txt', 'rt-polarity-neg.txt']\n",
    "\n",
    "def labeler(example, index):\n",
    "  return example, tf.cast(index, tf.int64)\n",
    "\n",
    "labeled_data_sets = []\n",
    "\n",
    "for i, file_name in enumerate(FILE_NAMES):\n",
    "    text_dir = os.path.join(parent_dir, file_name)\n",
    "    print(text_dir)\n",
    "    \n",
    "    lines_dataset = tf.data.TextLineDataset(text_dir)\n",
    "    labeled_dataset = lines_dataset.map(lambda ex: labeler(ex, i))\n",
    "    labeled_data_sets.append(labeled_dataset)\n",
    "\n",
    "labeled_data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: id=53, shape=(), dtype=string, numpy=b\"there's not a single jump-in-your-seat moment and believe it or not , jason actually takes a backseat in his own film to special effects . \">, <tf.Tensor: id=54, shape=(), dtype=int64, numpy=1>)\n",
      "(<tf.Tensor: id=55, shape=(), dtype=string, numpy=b\"kirshner and monroe seem to be in a contest to see who can out-bad-act the other . ( kirshner wins , but it's close . ) \">, <tf.Tensor: id=56, shape=(), dtype=int64, numpy=1>)\n",
      "(<tf.Tensor: id=57, shape=(), dtype=string, numpy=b'by no means a slam-dunk and sure to ultimately disappoint the action fans who will be moved to the edge of their seats by the dynamic first act , it still comes off as a touching , transcendent love story . '>, <tf.Tensor: id=58, shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: id=59, shape=(), dtype=string, numpy=b\"instead of accurately accounting a terrible true story , the film's more determined to become the next texas chainsaw massacre . but what about the countless other people who'd merely like to watch a solid tale about a universally interesting soul ? \">, <tf.Tensor: id=60, shape=(), dtype=int64, numpy=1>)\n",
      "(<tf.Tensor: id=61, shape=(), dtype=string, numpy=b'tries to work in the same vein as the brilliance of animal house but instead comes closer to the failure of the third revenge of the nerds sequel . '>, <tf.Tensor: id=62, shape=(), dtype=int64, numpy=1>)\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = 50000\n",
    "BATCH_SIZE = 64\n",
    "TAKE_SIZE = 5000\n",
    "\n",
    "all_labeled_data = labeled_data_sets[0]\n",
    "for labeled_dataset in labeled_data_sets[1:]:\n",
    "  all_labeled_data = all_labeled_data.concatenate(labeled_dataset)\n",
    "\n",
    "all_labeled_data = all_labeled_data.shuffle(\n",
    "    BUFFER_SIZE, reshuffle_each_iteration=False)\n",
    "\n",
    "for ex in all_labeled_data.take(5):\n",
    "  print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18369"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "\n",
    "vocabulary_set = set()\n",
    "for text_tensor, _ in all_labeled_data:\n",
    "  some_tokens = tokenizer.tokenize(text_tensor.numpy())\n",
    "  vocabulary_set.update(some_tokens)\n",
    "\n",
    "vocab_size = len(vocabulary_set)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"there's not a single jump-in-your-seat moment and believe it or not , jason actually takes a backseat in his own film to special effects . \"\n"
     ]
    }
   ],
   "source": [
    "example_text = next(iter(all_labeled_data))[0].numpy()\n",
    "print(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2803, 12906, 11165, 3131, 15047, 16760, 878, 16337, 17814, 4123, 2094, 8226, 8473, 10792, 11165, 14325, 7672, 15458, 3131, 2434, 878, 14483, 2150, 11494, 1320, 18140, 15985]\n"
     ]
    }
   ],
   "source": [
    "encoded_example = encoder.encode(example_text)\n",
    "print(encoded_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ShuffleDataset shapes: ((), ()), types: (tf.string, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "print(all_labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text_tensor, label):\n",
    "  encoded_text = encoder.encode(text_tensor.numpy())\n",
    "  return encoded_text, label\n",
    "\n",
    "def encode_map_fn(text, label):\n",
    "  return tf.py_function(encode, inp=[text, label], Tout=(tf.int64, tf.int64))\n",
    "\n",
    "all_encoded_data = all_labeled_data.map(encode_map_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into test and train batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PaddedBatchDataset shapes: ((None, None), (None,)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = all_encoded_data.skip(TAKE_SIZE).shuffle(BUFFER_SIZE)\n",
    "train_data = train_data.padded_batch(BATCH_SIZE, padded_shapes=([-1],[]))\n",
    "\n",
    "test_data = all_encoded_data.take(TAKE_SIZE)\n",
    "test_data = test_data.padded_batch(BATCH_SIZE, padded_shapes=([-1],[]))\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=21634, shape=(41,), dtype=int64, numpy=\n",
       " array([ 2803, 12906, 11165,  3131, 15047, 16760,   878, 16337, 17814,\n",
       "         4123,  2094,  8226,  8473, 10792, 11165, 14325,  7672, 15458,\n",
       "         3131,  2434,   878, 14483,  2150, 11494,  1320, 18140, 15985,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0])>,\n",
       " <tf.Tensor: id=21638, shape=(), dtype=int64, numpy=1>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text, sample_labels = next(iter(test_data))\n",
    "\n",
    "sample_text[0], sample_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Embedding(encoder.vocab_size, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.GlobalAveragePooling1D())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          293936    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 293,953\n",
      "Trainable params: 293,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "      1/Unknown - 3s 3s/step - loss: 0.6930 - accuracy: 0.5156WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.284215). Check your callbacks.\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.6917 - accuracy: 0.5297 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.6846 - accuracy: 0.7428 - val_loss: 0.6844 - val_accuracy: 0.6547\n",
      "Epoch 3/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.6724 - accuracy: 0.7566 - val_loss: 0.6759 - val_accuracy: 0.6714\n",
      "Epoch 4/100\n",
      "89/89 [==============================] - 2s 28ms/step - loss: 0.6538 - accuracy: 0.7833 - val_loss: 0.6644 - val_accuracy: 0.6786\n",
      "Epoch 5/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.6309 - accuracy: 0.7858 - val_loss: 0.6518 - val_accuracy: 0.6880\n",
      "Epoch 6/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.6047 - accuracy: 0.8038 - val_loss: 0.6377 - val_accuracy: 0.6880\n",
      "Epoch 7/100\n",
      "89/89 [==============================] - 2s 28ms/step - loss: 0.5770 - accuracy: 0.8204 - val_loss: 0.6240 - val_accuracy: 0.7000\n",
      "Epoch 8/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.5487 - accuracy: 0.8317 - val_loss: 0.6109 - val_accuracy: 0.7036\n",
      "Epoch 9/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.5226 - accuracy: 0.8428 - val_loss: 0.5987 - val_accuracy: 0.7109\n",
      "Epoch 10/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.4945 - accuracy: 0.8562 - val_loss: 0.5868 - val_accuracy: 0.7177\n",
      "Epoch 11/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.4706 - accuracy: 0.8635 - val_loss: 0.5760 - val_accuracy: 0.7219\n",
      "Epoch 12/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.4458 - accuracy: 0.8746 - val_loss: 0.5660 - val_accuracy: 0.7219\n",
      "Epoch 13/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.4237 - accuracy: 0.8841 - val_loss: 0.5566 - val_accuracy: 0.7328\n",
      "Epoch 14/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.4022 - accuracy: 0.8931 - val_loss: 0.5482 - val_accuracy: 0.7323\n",
      "Epoch 15/100\n",
      "89/89 [==============================] - 3s 32ms/step - loss: 0.3815 - accuracy: 0.9016 - val_loss: 0.5405 - val_accuracy: 0.7365\n",
      "Epoch 16/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.3627 - accuracy: 0.9092 - val_loss: 0.5338 - val_accuracy: 0.7385\n",
      "Epoch 17/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.3440 - accuracy: 0.9163 - val_loss: 0.5277 - val_accuracy: 0.7427\n",
      "Epoch 18/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.3261 - accuracy: 0.9241 - val_loss: 0.5223 - val_accuracy: 0.7474\n",
      "Epoch 19/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.3103 - accuracy: 0.9279 - val_loss: 0.5175 - val_accuracy: 0.7536\n",
      "Epoch 20/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.2941 - accuracy: 0.9339 - val_loss: 0.5144 - val_accuracy: 0.7563\n",
      "Epoch 21/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.2810 - accuracy: 0.9398 - val_loss: 0.5110 - val_accuracy: 0.7583\n",
      "Epoch 22/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.2688 - accuracy: 0.9435 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
      "Epoch 23/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.2555 - accuracy: 0.9493 - val_loss: 0.5054 - val_accuracy: 0.7646\n",
      "Epoch 24/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.2436 - accuracy: 0.9504 - val_loss: 0.5042 - val_accuracy: 0.7703\n",
      "Epoch 25/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.2327 - accuracy: 0.9548 - val_loss: 0.5024 - val_accuracy: 0.7693\n",
      "Epoch 26/100\n",
      "89/89 [==============================] - 3s 29ms/step - loss: 0.2229 - accuracy: 0.9594 - val_loss: 0.5017 - val_accuracy: 0.7719\n",
      "Epoch 27/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.2107 - accuracy: 0.9610 - val_loss: 0.5010 - val_accuracy: 0.7688\n",
      "Epoch 28/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.2034 - accuracy: 0.9647 - val_loss: 0.5010 - val_accuracy: 0.7682\n",
      "Epoch 29/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.1926 - accuracy: 0.9670 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 30/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.1863 - accuracy: 0.9694 - val_loss: 0.5017 - val_accuracy: 0.7698\n",
      "Epoch 31/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.1776 - accuracy: 0.9724 - val_loss: 0.5026 - val_accuracy: 0.7703\n",
      "Epoch 32/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.1711 - accuracy: 0.9733 - val_loss: 0.5043 - val_accuracy: 0.7688\n",
      "Epoch 33/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.1632 - accuracy: 0.9758 - val_loss: 0.5050 - val_accuracy: 0.7693\n",
      "Epoch 34/100\n",
      "89/89 [==============================] - 3s 29ms/step - loss: 0.1533 - accuracy: 0.9765 - val_loss: 0.5071 - val_accuracy: 0.7672\n",
      "Epoch 35/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.1486 - accuracy: 0.9774 - val_loss: 0.5087 - val_accuracy: 0.7677\n",
      "Epoch 36/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.1422 - accuracy: 0.9795 - val_loss: 0.5105 - val_accuracy: 0.7656\n",
      "Epoch 37/100\n",
      "89/89 [==============================] - 3s 29ms/step - loss: 0.1364 - accuracy: 0.9804 - val_loss: 0.5142 - val_accuracy: 0.7615\n",
      "Epoch 38/100\n",
      "89/89 [==============================] - 3s 28ms/step - loss: 0.1320 - accuracy: 0.9811 - val_loss: 0.5153 - val_accuracy: 0.7672\n",
      "Epoch 39/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.1261 - accuracy: 0.9815 - val_loss: 0.5192 - val_accuracy: 0.7583\n",
      "Epoch 40/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.1213 - accuracy: 0.9832 - val_loss: 0.5224 - val_accuracy: 0.7589\n",
      "Epoch 41/100\n",
      "89/89 [==============================] - 2s 28ms/step - loss: 0.1168 - accuracy: 0.9843 - val_loss: 0.5234 - val_accuracy: 0.7641\n",
      "Epoch 42/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.1108 - accuracy: 0.9852 - val_loss: 0.5265 - val_accuracy: 0.7620\n",
      "Epoch 43/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.1072 - accuracy: 0.9862 - val_loss: 0.5297 - val_accuracy: 0.7594\n",
      "Epoch 44/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.1033 - accuracy: 0.9859 - val_loss: 0.5350 - val_accuracy: 0.7573\n",
      "Epoch 45/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0992 - accuracy: 0.9873 - val_loss: 0.5367 - val_accuracy: 0.7583\n",
      "Epoch 46/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0940 - accuracy: 0.9887 - val_loss: 0.5403 - val_accuracy: 0.7573\n",
      "Epoch 47/100\n",
      "89/89 [==============================] - 2s 28ms/step - loss: 0.0913 - accuracy: 0.9883 - val_loss: 0.5441 - val_accuracy: 0.7557\n",
      "Epoch 48/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0886 - accuracy: 0.9889 - val_loss: 0.5508 - val_accuracy: 0.7505\n",
      "Epoch 49/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0840 - accuracy: 0.9894 - val_loss: 0.5515 - val_accuracy: 0.7547\n",
      "Epoch 50/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0813 - accuracy: 0.9894 - val_loss: 0.5558 - val_accuracy: 0.7552\n",
      "Epoch 51/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.0778 - accuracy: 0.9913 - val_loss: 0.5615 - val_accuracy: 0.7505\n",
      "Epoch 52/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0749 - accuracy: 0.9912 - val_loss: 0.5646 - val_accuracy: 0.7568\n",
      "Epoch 53/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.0733 - accuracy: 0.9912 - val_loss: 0.5689 - val_accuracy: 0.7557\n",
      "Epoch 54/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0694 - accuracy: 0.9919 - val_loss: 0.5737 - val_accuracy: 0.7536\n",
      "Epoch 55/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0664 - accuracy: 0.9926 - val_loss: 0.5774 - val_accuracy: 0.7547\n",
      "Epoch 56/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0643 - accuracy: 0.9921 - val_loss: 0.5824 - val_accuracy: 0.7542\n",
      "Epoch 57/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0626 - accuracy: 0.9924 - val_loss: 0.5874 - val_accuracy: 0.7521\n",
      "Epoch 58/100\n",
      "89/89 [==============================] - 2s 25ms/step - loss: 0.0597 - accuracy: 0.9924 - val_loss: 0.5922 - val_accuracy: 0.7526\n",
      "Epoch 59/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.0576 - accuracy: 0.9938 - val_loss: 0.5981 - val_accuracy: 0.7490\n",
      "Epoch 60/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.0552 - accuracy: 0.9943 - val_loss: 0.6067 - val_accuracy: 0.7484\n",
      "Epoch 61/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0533 - accuracy: 0.9935 - val_loss: 0.6094 - val_accuracy: 0.7505\n",
      "Epoch 62/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.0507 - accuracy: 0.9945 - val_loss: 0.6128 - val_accuracy: 0.7505\n",
      "Epoch 63/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.0494 - accuracy: 0.9949 - val_loss: 0.6178 - val_accuracy: 0.7505\n",
      "Epoch 64/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0477 - accuracy: 0.9951 - val_loss: 0.6233 - val_accuracy: 0.7490\n",
      "Epoch 65/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0455 - accuracy: 0.9956 - val_loss: 0.6284 - val_accuracy: 0.7500\n",
      "Epoch 66/100\n",
      "89/89 [==============================] - 3s 28ms/step - loss: 0.0443 - accuracy: 0.9956 - val_loss: 0.6352 - val_accuracy: 0.7526\n",
      "Epoch 67/100\n",
      "89/89 [==============================] - 2s 28ms/step - loss: 0.0427 - accuracy: 0.9951 - val_loss: 0.6416 - val_accuracy: 0.7526\n",
      "Epoch 68/100\n",
      "89/89 [==============================] - 2s 28ms/step - loss: 0.0408 - accuracy: 0.9959 - val_loss: 0.6467 - val_accuracy: 0.7521\n",
      "Epoch 69/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.0398 - accuracy: 0.9958 - val_loss: 0.6508 - val_accuracy: 0.7505\n",
      "Epoch 70/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0382 - accuracy: 0.9963 - val_loss: 0.6584 - val_accuracy: 0.7516\n",
      "Epoch 71/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0369 - accuracy: 0.9966 - val_loss: 0.6624 - val_accuracy: 0.7490\n",
      "Epoch 72/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0352 - accuracy: 0.9966 - val_loss: 0.6689 - val_accuracy: 0.7490\n",
      "Epoch 73/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.0343 - accuracy: 0.9968 - val_loss: 0.6737 - val_accuracy: 0.7469\n",
      "Epoch 74/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0326 - accuracy: 0.9970 - val_loss: 0.6803 - val_accuracy: 0.7490\n",
      "Epoch 75/100\n",
      "89/89 [==============================] - 2s 28ms/step - loss: 0.0321 - accuracy: 0.9968 - val_loss: 0.6879 - val_accuracy: 0.7453\n",
      "Epoch 76/100\n",
      "89/89 [==============================] - 3s 29ms/step - loss: 0.0304 - accuracy: 0.9972 - val_loss: 0.6930 - val_accuracy: 0.7484\n",
      "Epoch 77/100\n",
      "89/89 [==============================] - 3s 28ms/step - loss: 0.0297 - accuracy: 0.9972 - val_loss: 0.7000 - val_accuracy: 0.7469\n",
      "Epoch 78/100\n",
      "89/89 [==============================] - 2s 28ms/step - loss: 0.0278 - accuracy: 0.9974 - val_loss: 0.7054 - val_accuracy: 0.7490\n",
      "Epoch 79/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0274 - accuracy: 0.9975 - val_loss: 0.7118 - val_accuracy: 0.7490\n",
      "Epoch 80/100\n",
      "89/89 [==============================] - 2s 25ms/step - loss: 0.0268 - accuracy: 0.9975 - val_loss: 0.7179 - val_accuracy: 0.7490\n",
      "Epoch 81/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0254 - accuracy: 0.9977 - val_loss: 0.7254 - val_accuracy: 0.7479\n",
      "Epoch 82/100\n",
      "89/89 [==============================] - 2s 28ms/step - loss: 0.0247 - accuracy: 0.9975 - val_loss: 0.7304 - val_accuracy: 0.7458\n",
      "Epoch 83/100\n",
      "89/89 [==============================] - 2s 28ms/step - loss: 0.0233 - accuracy: 0.9979 - val_loss: 0.7385 - val_accuracy: 0.7484\n",
      "Epoch 84/100\n",
      "89/89 [==============================] - 2s 28ms/step - loss: 0.0225 - accuracy: 0.9977 - val_loss: 0.7444 - val_accuracy: 0.7458\n",
      "Epoch 85/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.0223 - accuracy: 0.9979 - val_loss: 0.7554 - val_accuracy: 0.7469\n",
      "Epoch 86/100\n",
      "89/89 [==============================] - 2s 28ms/step - loss: 0.0205 - accuracy: 0.9981 - val_loss: 0.7667 - val_accuracy: 0.7464\n",
      "Epoch 87/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.0205 - accuracy: 0.9981 - val_loss: 0.7650 - val_accuracy: 0.7474\n",
      "Epoch 88/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.0199 - accuracy: 0.9982 - val_loss: 0.7712 - val_accuracy: 0.7464\n",
      "Epoch 89/100\n",
      "89/89 [==============================] - 2s 28ms/step - loss: 0.0190 - accuracy: 0.9981 - val_loss: 0.7795 - val_accuracy: 0.7448\n",
      "Epoch 90/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0184 - accuracy: 0.9981 - val_loss: 0.7872 - val_accuracy: 0.7432\n",
      "Epoch 91/100\n",
      "89/89 [==============================] - 3s 29ms/step - loss: 0.0175 - accuracy: 0.9982 - val_loss: 0.7934 - val_accuracy: 0.7432\n",
      "Epoch 92/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.0171 - accuracy: 0.9982 - val_loss: 0.8014 - val_accuracy: 0.7443\n",
      "Epoch 93/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0158 - accuracy: 0.9984 - val_loss: 0.8070 - val_accuracy: 0.7422\n",
      "Epoch 94/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.0156 - accuracy: 0.9988 - val_loss: 0.8149 - val_accuracy: 0.7427\n",
      "Epoch 95/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0148 - accuracy: 0.9988 - val_loss: 0.8194 - val_accuracy: 0.7443\n",
      "Epoch 96/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0146 - accuracy: 0.9989 - val_loss: 0.8284 - val_accuracy: 0.7432\n",
      "Epoch 97/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0137 - accuracy: 0.9991 - val_loss: 0.8393 - val_accuracy: 0.7479\n",
      "Epoch 98/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 0.0132 - accuracy: 0.9991 - val_loss: 0.8421 - val_accuracy: 0.7437\n",
      "Epoch 99/100\n",
      "89/89 [==============================] - 3s 28ms/step - loss: 0.0130 - accuracy: 0.9989 - val_loss: 0.8505 - val_accuracy: 0.7432\n",
      "Epoch 100/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.0126 - accuracy: 0.9993 - val_loss: 0.8619 - val_accuracy: 0.7464\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,\n",
    "                    epochs=100,\n",
    "                    validation_data=test_data,\n",
    "                    validation_steps=30,\n",
    "                    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_data)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a graph of accuracy and loss over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3de3zU1Z3/8deHa0DuF0VBCFoUQeViBBW0KtWiInQVFcR6K1L9KV7a7tYqra6K67autXVZ12i1tkUolaLY9Y5YELwQlICACiJgADEgIhAUAp/fH+cbMhknyQQymUnyfj4e88h8z/cyn0xgPnPO+Z5zzN0RERGJ1yDdAYiISGZSghARkYSUIEREJCElCBERSUgJQkREElKCEBGRhJQgJGlm1tDMtptZ1+o8Np3M7DtmVu33epvZ98xsdcz2h2Z2ajLH7sdrPWZmt+3v+SLlaZTuACR1zGx7zGZz4BtgT7T9Y3efXJXrufseoEV1H1sfuPvR1XEdMxsLXObup8dce2x1XFsknhJEHebu+z6go2+oY9391fKON7NG7l5cE7GJVEb/HtNPTUz1mJndY2Z/NbMpZrYNuMzMTjazt8zsSzPbYGa/N7PG0fGNzMzNLDva/ku0/wUz22Zmb5pZ96oeG+0/x8w+MrOtZvaQmc0zsyvLiTuZGH9sZivNbIuZ/T7m3IZm9lsz22xmq4ChFbw/t5vZ1LiySWb2QPR8rJktj36fj6Nv9+Vdq8DMTo+eNzezP0exLQVOiDt2gpmtiq671MyGR+XHAf8NnBo1322KeW/vjDn/2uh332xmz5jZocm8N1V5n0viMbNXzewLM/vMzP4t5nV+Gb0nX5lZnpkdlqg5z8zeKPk7R+/nnOh1vgAmmFkPM5sdvcam6H1rHXN+t+h3LIz2/87MsqKYj4k57lAzKzKz9uX9vpKAu+tRDx7AauB7cWX3ALuA8wlfFpoBJwIDCbXLI4CPgBui4xsBDmRH238BNgE5QGPgr8Bf9uPYg4FtwIho30+A3cCV5fwuycT4LNAayAa+KPndgRuApUAXoD0wJ/w3SPg6RwDbgYNirv05kBNtnx8dY8CZwE7g+Gjf94DVMdcqAE6Pnt8PvA60BboBy+KOvRg4NPqbXBrFcEi0byzwelycfwHujJ6fHcXYF8gC/gd4LZn3porvc2tgI3AT0BRoBQyI9v0CyAd6RL9DX6Ad8J349xp4o+TvHP1uxcB1QEPCv8ejgCFAk+jfyTzg/pjf5/3o/TwoOn5QtC8XmBjzOj8FZqT7/2Fte6Q9AD1q6A9dfoJ4rZLzfgb8LXqe6EP/f2OOHQ68vx/HXg3MjdlnwAbKSRBJxnhSzP6/Az+Lns8hNLWV7Ds3/kMr7tpvAZdGz88BPqzg2H8A10fPK0oQa2P/FsD/iz02wXXfB86LnleWIJ4E7o3Z14rQ79Slsvemiu/zD4EF5Rz3cUm8ceXJJIhVlcQwsuR1gVOBz4CGCY4bBHwCWLS9CLiguv9f1fWHmpjk09gNM+tpZv8XNRl8BdwFdKjg/M9inhdRccd0ecceFhuHh//RBeVdJMkYk3otYE0F8QI8BYyOnl8abZfEMczM3o6aP74kfHuv6L0qcWhFMZjZlWaWHzWTfAn0TPK6EH6/fddz96+ALUDnmGOS+ptV8j4fTkgEiVS0rzLx/x47mdk0M1sXxfDHuBhWe7ghogx3n0eojQw2s2OBrsD/7WdM9ZYShMTf4vkI4Rvrd9y9FfArwjf6VNpA+IYLgJkZZT/Q4h1IjBsIHywlKrsNdxrwPTPrTGgCeyqKsRnwNPAfhOafNsDLScbxWXkxmNkRwMOEZpb20XU/iLluZbfkric0W5VcryWhKWtdEnHFq+h9/hQ4spzzytu3I4qpeUxZp7hj4n+//yTcfXdcFMOVcTF0M7OG5cTxJ+AyQm1nmrt/U85xUg4lCInXEtgK7Ig6+X5cA6/5D6C/mZ1vZo0I7dodUxTjNOBmM+scdVj+vKKD3f0zQjPIHwnNSyuiXU0J7eKFwB4zG0ZoK082htvMrI2FcSI3xOxrQfiQLCTkymsINYgSG4EusZ3FcaYAPzKz482sKSGBzXX3cmtkFajofZ4JdDWzG8ysqZm1MrMB0b7HgHvM7EgL+ppZO0Ji/IxwM0RDMxtHTDKrIIYdwFYzO5zQzFXiTWAzcK+Fjv9mZjYoZv+fCU1SlxKShVSREoTE+ylwBaHT+BFCZ3JKuftG4BLgAcJ/+COB9wjfHKs7xoeBWcASYAGhFlCZpwh9Cvual9z9S+AWYAaho3ckIdEl4w5CTWY18AIxH17uvhh4CHgnOuZo4O2Yc18BVgAbzSy2qajk/BcJTUEzovO7AmOSjCteue+zu28FzgIuJCStj4DvRrt/AzxDeJ+/InQYZ0VNh9cAtxFuWPhO3O+WyB3AAEKimglMj4mhGBgGHEOoTawl/B1K9q8m/J2/cff5VfzdhdIOHJGMETUZrAdGuvvcdMcjtZeZ/YnQ8X1numOpjTRQTjKCmQ0l3DG0k3Cb5G7Ct2iR/RL154wAjkt3LLWVmpgkUwwGVhHa3r8P/Is6FWV/mdl/EMZi3Ovua9MdT22lJiYREUlINQgREUmozvRBdOjQwbOzs9MdhohIrbJw4cJN7p7wtvI6kyCys7PJy8tLdxgiIrWKmZU7m4CamEREJCElCBERSUgJQkREElKCEBGRhJQgREQkISUIEZFaavJkyM6GBg3Cz8mTq/f6deY2VxGR+mTyZBg3DoqKwvaaNWEbYMz+zt8bRzUIEZFa6PbbS5NDiaKiUF5dlCBERGqhteVMQVhe+f5QghARqYW6lrNYbnnl+0MJQkSkFpo4EZo3L1vWvHkory5KECIitdCYMZCbC926gVn4mZtbfR3UkOIEYWZDzexDM1tpZrcm2N/VzGab2XtmttjMzo3Ks81sp5ktih7/m8o4RURqozFjYPVq2Ls3/KzO5AApvM01Wld4EmFh8wJggZnNdPdlMYdNAKa5+8Nm1gt4HsiO9n3s7n1TFZ+IiFQslTWIAcBKd1/l7ruAqYT1YWM50Cp63pqwUL2IiGSAVCaIzsCnMdsFUVmsO4HLzKyAUHsYH7Ove9T09E8zOzXRC5jZODPLM7O8wsLCagxdRKR8qR7BnCnS3Uk9Gviju3cBzgX+bGYNgA1AV3fvB/wEeMrMWsWf7O657p7j7jkdOyZcEElEpFqVjGBeswbcS0cw18UkkcoEsQ44PGa7S1QW60fANAB3fxPIAjq4+zfuvjkqXwh8DByVwlhFRJJSEyOYM0UqE8QCoIeZdTezJsAoYGbcMWuBIQBmdgwhQRSaWceokxszOwLoAaxKYawiIkmpiRHMmSJlCcLdi4EbgJeA5YS7lZaa2V1mNjw67KfANWaWD0wBrnR3B04DFpvZIuBp4Fp3/yJVsYqIJKsmRjBnCgufx7VfTk6O5+XlpTsMEanj4mdRhTCCuboHqdUUM1vo7jmJ9qW7k1pEpFapiRHMmULrQYiIVNGYMXUzIcRTDUJERBJSghARkYSUIEREJCElCBERSUgJQkREElKCEJFao75MkpcpdJuriNQK8QPUSibJg/pxy2k6qAYhIrVCfZokL1MoQYhIrVCfJsnLFEoQIpKUdLf/16dJ8jKFEoSIVCoTFsmZODFMiherefNQLqmhBCEilcqE9v/6NEleptB03yJSqQYNQs0hnhns3Vvz8Uj10XTfInJA1P5fPylBiEil1P5fPylBiEil1P5fP2kktYgkpb4skiOlVIMQEZGElCBERCQhJQgREUlICUJERBJSghARkYSUIEREJKGUJggzG2pmH5rZSjO7NcH+rmY228zeM7PFZnZuzL5fROd9aGbfT2WcIiLybSkbB2FmDYFJwFlAAbDAzGa6+7KYwyYA09z9YTPrBTwPZEfPRwG9gcOAV83sKHffk6p4RUSkrFTWIAYAK919lbvvAqYCI+KOcaBV9Lw1sD56PgKY6u7fuPsnwMroeiIiUkNSmSA6A5/GbBdEZbHuBC4zswJC7WF8Fc7FzMaZWZ6Z5RUWFlZX3CIiQvo7qUcDf3T3LsC5wJ/NLOmY3D3X3XPcPadjx44pC1IkndK9kpvUX6mci2kdcHjMdpeoLNaPgKEA7v6mmWUBHZI8V6TOK1nJrWSxnpKV3EDzIknqpbIGsQDoYWbdzawJodN5Ztwxa4EhAGZ2DJAFFEbHjTKzpmbWHegBvJPCWEUyUias5Cb1V8pqEO5ebGY3AC8BDYHH3X2pmd0F5Ln7TOCnwKNmdguhw/pKD0vcLTWzacAyoBi4XncwSX20dm3VykWqk5YcFclg2dmhWSlet26wenVNRyN1kZYcFamltJKbpJMShEgG00pukk5aUU4kw2klN0kX1SBERCQhJQgREUlICUJERBJSghARkYSUIEREJCElCJFyaJI8qe90m6tIApokT0Q1CJGENEmeiBKESEKaJE9ECUIyUCa0/XftWrVykbpICUIySknb/5o14F7a9l/TSUKT5IkoQUiGyZS2f02SJ6L1ICTDNGgQag7xzGDv3pqPR6Su03oQUmuo7V8kcyhBSEZR279I5lCCkIyitn+RzKGR1JJxtECOSGZQDUJERBJSghARkYSUIEREJCElCBERSUgJQkREEkppgjCzoWb2oZmtNLNbE+z/rZktih4fmdmXMfv2xOybmco4RUTk21J2m6uZNQQmAWcBBcACM5vp7stKjnH3W2KOHw/0i7nETnfvm6r4RESkYqmsQQwAVrr7KnffBUwFRlRw/GhgSgrjERGRKkhlgugMfBqzXRCVfYuZdQO6A6/FFGeZWZ6ZvWVmPyjnvHHRMXmFhYXVFbeIiJA5ndSjgKfdfU9MWbdohsFLgQfN7Mj4k9w9191z3D2nY8eONRWriEi9kMoEsQ44PGa7S1SWyCjimpfcfV30cxXwOmX7J0REJMVSmSAWAD3MrLuZNSEkgW/djWRmPYG2wJsxZW3NrGn0vAMwCFgWf66IiKROpQnCzMabWduqXtjdi4EbgJeA5cA0d19qZneZ2fCYQ0cBU73sykXHAHlmlg/MBu6LvftJRERSL5kaxCGEW1SnReMaLNmLu/vz7n6Uux/p7hOjsl+5+8yYY+5091vjzpvv7se5e5/o5x+SfU3Zf5MnQ3Z2WNUtO7vm14EWkcxSaYJw9wlAD+APwJXACjO7N1GnsdRekyfDuHGwZk1Y8nPNmrCtJCFSfyXVBxE1/3wWPYoJfQZPm9mvUxib1KDbb4eiorJlRUWhXETqp0pHUpvZTcDlwCbgMeBf3X23mTUAVgD/ltoQpSasXVu1chGp+5KZaqMdcIG7r4ktdPe9ZjYsNWFJTevaNTQrJSoXkfopmSamF4AvSjbMrJWZDQRw9+WpCkxq1sSJ0Lx52bLmzUO5iNRPySSIh4HtMdvbozKpQ8aMgdxc6NYNzMLP3FytDS1SnyXTxGSxYxSipqWUzQIr6TNmjBKCiJRKpgaxysxuNLPG0eMmYFWqAxMRkfRKJkFcC5xCmEepABgIjEtlUCIikn6VNhW5++eE6TBERKQeSWYcRBbwI6A3kFVS7u5XpzAuERFJs2SamP4MdAK+D/yTMG33tlQGJSIi6ZdMgviOu/8S2OHuTwLnEfohRESkDksmQeyOfn5pZscCrYGDUxeSiIhkgmTGM+RG60FMICz40wL4ZUqjEhGRtKswQUQT8n3l7luAOcARNRKViEgd5w579sDeveFn/POK9sU/b9YMevas/hgrTBDRqOl/A6ZV/0uLiKTXrl2wbRt89VX4Wd7z8sqKivb/A77MGpoHaOBAeOut6rteiWSamF41s58BfwV2lBS6+xflnyIikhru8MUXsHXr/n+wl5R9801yr9m8ObRsGR6tWoWfXbqE8kaNwiqMDRuGRzLPkz0u2XPatUvNe51Mgrgk+nl9TJmj5iYRqQHFxbBoEcyfD/Pmhce6dZWf16LFtz/Uu3UrfR5bnqis5HmLFiEJ1EfJjKTuXhOBiIhAqBm8+WZpMnj77dLVDg8/HE49FU48ETp0KP9D/aCDwjdrOTDJjKS+PFG5u/+p+sMRkfrEHVavLk0G8+bB+++H8gYNoG9f+NGPYNAgOOWUkCCk5iRTcTox5nkWMAR4F1CCEJEq2b0b3nuvNBnMnw8bNoR9LVvCySfDyJEhIQwcGJp3JH2SaWIaH7ttZm2AqSmLSETqjC1byjYXvfMO7NwZ9mVnw5lnhprBoEFw7LFqFso0+9P1sgNQv4SIlOEOH39cWjOYNw+WLg37GjaEfv1g3LiQDAYNgsMOS2+8Urlk+iCeI9y1BGFqjl5oXIRIvbdrF7z7btnmoo0bw77WrUNz0ahRIRkMGBA6jqV2SaYGcX/M82JgjbsXJHNxMxsK/A5oCDzm7vfF7f8tcEa02Rw42N3bRPuuIEzvAXBPNFGgiKTJ7t3w6qswZ05ICAsWwNdfh31HHAFnn11aO+jVK3QyS+2WTIJYC2xw968BzKyZmWW7++qKTjKzhsAk4CzCSnQLzGymuy8rOcbdb4k5fjzQL3reDrgDyCHUXhZG526pyi8nIgfu44/hscfgiSdCDaFRI+jfH667rvTuokMPTXeUkgrJJIi/EZYcLbEnKjsx8eH7DABWuvsqADObCowAlpVz/GhCUoCw9sQrJaO1zewVYCgwJYl4ReQA7doFzz4Lubmh1tCgAQwbBmPHwpAhYQSx1H3JJIhG7r6rZMPdd5lZkyTO6wx8GrNdsp71t5hZN0LH92sVnNs5wXnjiNbH7tq1axIhiUhFVqyARx+FP/4RCguha1e4+2646iro/K3/gVLXJZMgCs1suLvPBDCzEcCmao5jFPC0u++pyknungvkAuTk5FTj1Fci9cc338CMGaG2MHt2uONo+PBwx9FZZ+nW0/osmQRxLTDZzP472i4AEo6ujrMOiB332CUqS2QUZed6WgecHnfu60m8pogk6YMPQm3hySdh82bo3h3uvReuvFJ9ChIkM1DuY+AkM2sRbW9P8toLgB5m1p3wgT8KuDT+IDPrCbQF3owpfgm4N1qoCOBs4BdJvq6IlGPnTpg+PdQW5s4NHc4/+EGoLQwZojuPpKxK/zmY2b1m1sbdt7v7djNra2b3VHaeuxcDNxA+7JcD09x9qZndZWbDYw4dBUx1L50dPeqcvpuQZBYAd2l6cZH9t3Qp3HRT6Ef44Q/D9Bb/+Z9QUAB/+1toSlJykHjmlaxaYWbvuXu/uLJ33b1/SiOropycHM/Ly0t3GCIZo6gofPjn5oZBbI0bw4UXwjXXwOmnKyFIYGYL3T0n0b5k+iAamllTd/8mulgzoGl1Bigi1Wfx4pAU/vKXMHX2UUfB/ffD5ZdDx47pjk5qk2QSxGRglpk9ARhwJaBRzSIZZMcO+OtfQ2J4+21o2jTMijpuXFg/wSzdEUptlEwn9X+aWT7wPcKo5peAbqkOTEQq9957ISlMnhyW0OzVCx58MPQzpGoZSqk/kp3NdSMhOVwEfAJMT1lEIlKhbdtgypRwi2peHmRlwcUXh9rCKaeotiDVp9wEYWZHEaa/GE0YGPdXQqf2GeWdIyKp4Q4LF4bawlNPhSal446Dhx6CMWOgbdvKryFSVRXVID4A5gLD3H0lgJndUsHxIlKNPvssjFWYOxdeey3cqtq8eZhC+5prwoprqi1IKlWUIC4gjFGYbWYvElaR0z9HkRQoWZt57twwnfacOWFeJAhJ4eST4f/9v1BbaN06raFKPVJugnD3Z4BnzOwgwiysNwMHm9nDwAx3f7mGYhSpc/buheXLSxPC3Llh0BqE5qLBg0vvQOrfP4xhEKlpydzFtAN4CngqmvriIuDngBKESJKKi2HRotJkMHdumP8IwrxHp50WksFpp0Hv3hrEJpmhSmtSRwv27JtBVUQS+/preOed0oQwfz5sj2YxO/JIOP/8kAxOOy2sxqa+BMlEVUoQIpLYV1+FJFDSZPTOO2HRHQh3G11+eWkt4bDD0hurSLKUIET2Q2EhvPFGaYfyokWhX6FhQzjhBLjxxpAMBg/WgDWpvZQgRJKwdm3ZDuXly0N5VhacdBLcfnuoIZx0ErRokd5YRaqLEoRIAnv2wOuvw9Sp8MorsGZNKG/VCgYNCk1Gp54KOTlh3iORukgJQiSydy+89VaYxuJvf4ONG0Nt4Oyz4ZZbQg3h+OO1BKfUH0oQUq+5h/6DKVPCbKhr14YawbBhYcTyeedBs2bpjlIkPZQgpF764IPQfDR1Knz4YVh68+yzYeJEGD48NCWJ1HdKEFJvrF4daglTpkB+fhh7cPrp8JOfhJXW2rdPd4QimUUJQuq0DRtCf8KUKaF/AcKdRg8+CBddpDEJIhVRgpA6Z/Nm+PvfQ1J4/fXQz9CnD/zHf8All0D37umOUKR2UIKQOmHbNnj22ZAUXn45zH3Uowf88pehs/mYY9IdoUjtowQhtdbOnfD886Gj+R//CPMfHX54uCV19Gjo21dzHIkcCCUIqVV27w4D16ZOhWeeCTWHgw+GsWNDTeHkkzUTqkh1UYKQjLdnT5jiYsoUmD4dvvgC2rQJ6zCPGhXuRGqkf8ki1U7/rSQj7d0bZkSdOhWmTQt3Ix10EIwYEZLC978PTZqkO0qRui2lCcLMhgK/AxoCj7n7fQmOuRi4E3Ag390vjcr3AEuiw9a6+/BUxio1Y/v2sNbyhg3hZ3mPjRtDzaFpUzj33JAUhg0Ly2+KSM1IWYIws4bAJOAsoABYYGYz3X1ZzDE9gF8Ag9x9i5kdHHOJne7eN1XxSfXZvRs+/zy5D/4dO759fsOGcMgh0KlTePTtG3727BlGNWsNZpH0SGUNYgCw0t1XAZjZVMLa1stijrkGmBStVIe7f57CeKQK3GHLltIP9oo++DdtSnyNtm1LP/QHDCh9Hv9o314T4IlkolQmiM7ApzHbBcDAuGOOAjCzeYRmqDvd/cVoX5aZ5QHFwH3u/kz8C5jZOGAcQNeuXas3+nrk669hwQKYNy+sipafHxLC7t3fPrZp07CGcqdO8J3vhAVx4j/wDz003FmUlVXzv4uIVJ90d1I3AnoApwNdgDlmdpy7fwl0c/d1ZnYE8JqZLXH3j2NPdvd962Pn5OR4zYZee23cGBLBvHnhsXBhaTI4+uiwzkGXLmU/8Euet2qlsQUi9UUqE8Q64PCY7S5RWawC4G133w18YmYfERLGAndfB+Duq8zsdaAf8DFSJXv3htXPSpLB/PmwcmXY16QJnHhiGFg2aBCccgp06JDeeEUkc6QyQSwAephZd0JiGAVcGnfMM8Bo4Akz60BoclplZm2BInf/JiofBPw6hbHWGUVFpc1F8+bBm2+GvgSAjh1DEhg3LiSEE07QamgiUr6UJQh3LzazG4CXCP0Lj7v7UjO7C8hz95nRvrPNbBmwB/hXd99sZqcAj5jZXqABoQ9iWTkvVa9t2FBaM5g3D959N8xDBGH+oQsvDMlg0KDQZ6DmIRFJlrnXjab7nJwcz8vLS3cYKbV3LyxdWlo7mDcPPvkk7MvKCs1FJcng5JO1voGIVM7MFrp7TqJ96e6klgrs2BFGE8c2F23dGvYdfHBIBNdfH37276+RxSJSvZQgMsj69fDGG6UJYdGiMJoYoHfvsJZBSQ3hiCPUXCQiqaUEkSGeeCLMSLp3LzRrFgaW/fznpc1FbdumO0IRqW+UIDLAM8+E5HDmmTBxIvTrB40bpzsqEanvlCDS7PXXw0R0J54IM2ZAixbpjkhEJNDSKmn03nthMrr27WHdujBKOTsbJk9Od2QiIqpBpM2KFTB0aLjz6IsvwnxIAGvWhIFsAGPGpC8+ERHVINJg/Xo4++zQId20aWlyKFFUBLffnp7YRERKKEHUsC1bwmpomzbBiy+GkdCJrF1bs3GJiMRTgqhBO3aEVdE++giefTbMhVTeLOWavVxE0k0Joobs3g0XXQRvvQVTpoRbWiHc1hq/jGbz5qFcRCSdlCBqwN69cOWV8MIL8L//CxdcULpvzBjIzYVu3cLI6G7dwrY6qEUk3XQXU4q5w803w1NPwb33wjXXfPuYMWOUEEQk86gGkWL33AMPPQQ/+Qncemu6oxERSZ4SRAo9/DD86ldw+eXwm99ocj0RqV2UIFJk2rQwFfewYfDYY9BA77SI1DL62EqBl1+Gyy6DwYNDotDEeyJSGylBVLO33w53KfXqBTNnhqm7RURqIyWIarRsGZx7LnTqFEZJt2mT7ohERPafEkQ1Wbs2TKHRpEloYurUKd0RiYgcGI2DqAaFhWHyvW3bYM6csByoiEhtpwRxgLZtC81Ka9bAK6/A8cenOyKRmrd7924KCgr4On5qYskYWVlZdOnShcZVuGtGCeIAfPMN/OAHYeGfZ58Ndy2J1EcFBQW0bNmS7OxsTAN+Mo67s3nzZgoKCujevXvS56kPYj/t2ROmx3jtNXjiCTjvvHRHJJI+X3/9Ne3bt1dyyFBmRvv27atcw1OC2A/ucN11MH06/Pa38MMfpjsikfRTcshs+/P3SWmCMLOhZvahma00s4QzEZnZxWa2zMyWmtlTMeVXmNmK6HFFKuOsqgkT4NFH4bbbwkR8IiJ1UcoShJk1BCYB5wC9gNFm1ivumB7AL4BB7t4buDkqbwfcAQwEBgB3mFnbVMVaFb/9bZiVddy4MBGfiFTd5MmQnR2moMnODtsHYvPmzfTt25e+ffvSqVMnOnfuvG97165dSV3jqquu4sMPP6zwmEmTJjH5QIOtRVLZST0AWOnuqwDMbCowAlgWc8w1wCR33wLg7p9H5d8HXnH3L6JzXwGGAlNSGG+l/vSnMCvrhRfC//yPJt8T2R+TJ4cvWEVFYXvNmrAN+z/tffv27Vm0aBEAd955Jy1atOBnP/tZmWPcHXenQTkToz3xxBOVvs7111+/fwHWUqlsYuoMfBqzXRCVxToKOMrM5pnZW2Y2tArnYmbjzCzPzPIKCwurMfRv+8c/4OqrYciQ8A+8YcOUvpxInXX77aXJoURRUSivbitXrqRXr16MGTOG3r17s2HDBsaNG0dOTg69e/fmrrvu2nfs4MGDWbRoEcXFxbRp04Zbb72VPn36cPLJJ/P55+G764QJE645vkUAAA68SURBVHjwwQf3HX/rrbcyYMAAjj76aObPnw/Ajh07uPDCC+nVqxcjR44kJydnX/KKdccdd3DiiSdy7LHHcu211+LuAHz00UeceeaZ9OnTh/79+7N69WoA7r33Xo477jj69OnD7al4sxJIdyd1I6AHcDowGnjUzJKeoMLdc909x91zOnbsmKIQYe7csFxov34wYwY0bZqylxKp89aurVr5gfrggw+45ZZbWLZsGZ07d+a+++4jLy+P/Px8XnnlFZYtW/atc7Zu3cp3v/td8vPzOfnkk3n88ccTXtvdeeedd/jNb36zL9k89NBDdOrUiWXLlvHLX/6S9957L+G5N910EwsWLGDJkiVs3bqVF198EYDRo0dzyy23kJ+fz/z58zn44IN57rnneOGFF3jnnXfIz8/npz/9aTW9OxVLZYJYBxwes90lKotVAMx0993u/gnwESFhJHNujcjPh/PPD0uBvvACtGyZjihE6o6uXatWfqCOPPJIcnJy9m1PmTKF/v37079/f5YvX54wQTRr1oxzzjkHgBNOOGHft/h4F0TrB8ce88YbbzBq1CgA+vTpQ+/evROeO2vWLAYMGECfPn345z//ydKlS9myZQubNm3i/PPPB8LgtubNm/Pqq69y9dVX0yya/bNdu3ZVfyP2QyoTxAKgh5l1N7MmwChgZtwxzxBqD5hZB0KT0yrgJeBsM2sbdU6fHZXVqFWrYOjQkBRefhk6dKjpCETqnokToXnzsmXNm4fyVDjooIP2PV+xYgW/+93veO2111i8eDFDhw5NODagSZMm+543bNiQ4uLihNduGjUnVHRMIkVFRdxwww3MmDGDxYsXc/XVV2fkKPSUJQh3LwZuIHywLwemuftSM7vLzIZHh70EbDazZcBs4F/dfXPUOX03IcksAO4q6bCuKZ99BmedBbt3h+SQqm83IvXNmDGQmxtq5WbhZ25uzazL/tVXX9GyZUtatWrFhg0beOml6v/eOWjQIKZNmwbAkiVLEtZQdu7cSYMGDejQoQPbtm1j+vTpALRt25aOHTvy3HPPAWEAYlFREWeddRaPP/44O3fuBOCLL2rm4zClU224+/PA83Flv4p57sBPokf8uY8DiRv+UuzLL8PMrBs3hpHSxxyTjihE6q4xY2omIcTr378/vXr1omfPnnTr1o1BgwZV+2uMHz+eyy+/nF69eu17tG7duswx7du354orrqBXr14ceuihDBw4cN++yZMn8+Mf/5jbb7+dJk2aMH36dIYNG0Z+fj45OTk0btyY888/n7vvvrvaY49nJT3ntV1OTo7n5eUd8HWKikJyePtt+L//C7UIEanY8uXLOUbfpAAoLi6muLiYrKwsVqxYwdlnn82KFSto1Cj9U98l+juZ2UJ3z0l0fPojziC7d8Mll8C8eTB1qpKDiFTd9u3bGTJkCMXFxbg7jzzySEYkh/1RO6NOgb17YezYMN7h4Yfh4ovTHZGI1EZt2rRh4cKF6Q6jWqR7HERGcIef/SyMlL7rLrj22nRHJCKSfkoQwH33hTmWbrwxTMQnIiJKEHzwQUgKY8aEJKH5lUREgnrfB9GzJ7z6algNrpw5vERE6iV9JAJnnAFVWKZVRDLMGWec8a1Bbw8++CDXXXddhee1aNECgPXr1zNy5MiEx5x++ulUdgv9gw8+SFHMDITnnnsuX375ZTKhZzQlCBGp9UaPHs3UqVPLlE2dOpXRo0cndf5hhx3G008/vd+vH58gnn/+edq0SXre0YxV75uYRKR63XwzJJjd+oD07QvRLNsJjRw5kgkTJrBr1y6aNGnC6tWrWb9+Paeeeirbt29nxIgRbNmyhd27d3PPPfcwYsSIMuevXr2aYcOG8f7777Nz506uuuoq8vPz6dmz577pLQCuu+46FixYwM6dOxk5ciT//u//zu9//3vWr1/PGWecQYcOHZg9ezbZ2dnk5eXRoUMHHnjggX2zwY4dO5abb76Z1atXc8455zB48GDmz59P586defbZZ/dNxlfiueee45577mHXrl20b9+eyZMnc8ghh7B9+3bGjx9PXl4eZsYdd9zBhRdeyIsvvshtt93Gnj176NChA7NmzTqg910JQkRqvXbt2jFgwABeeOEFRowYwdSpU7n44osxM7KyspgxYwatWrVi06ZNnHTSSQwfPrzcNZoffvhhmjdvzvLly1m8eDH9+/fft2/ixIm0a9eOPXv2MGTIEBYvXsyNN97IAw88wOzZs+kQN6PnwoULeeKJJ3j77bdxdwYOHMh3v/td2rZty4oVK5gyZQqPPvooF198MdOnT+eyyy4rc/7gwYN56623MDMee+wxfv3rX/Nf//Vf3H333bRu3ZolS5YAsGXLFgoLC7nmmmuYM2cO3bt3r5b5mpQgRKRaVfRNP5VKmplKEsQf/vAHIKzZcNtttzFnzhwaNGjAunXr2LhxI506dUp4nTlz5nDjjTcCcPzxx3P88cfv2zdt2jRyc3MpLi5mw4YNLFu2rMz+eG+88Qb/8i//sm9G2QsuuIC5c+cyfPhwunfvTt++fYHypxQvKCjgkksuYcOGDezatYvu3bsD8Oqrr5ZpUmvbti3PPfccp5122r5jqmNK8HrfB1Hda+OKSHqMGDGCWbNm8e6771JUVMQJJ5wAhMnvCgsLWbhwIYsWLeKQQw7Zr6m1P/nkE+6//35mzZrF4sWLOe+88w5oiu6mMSuPlTdd+Pjx47nhhhtYsmQJjzzySI1PCV6vE0TJ2rhr1oTR1CVr4ypJiNQ+LVq04IwzzuDqq68u0zm9detWDj74YBo3bszs2bNZs2ZNhdc57bTTeOqppwB4//33Wbx4MRCmCj/ooINo3bo1Gzdu5IUXXth3TsuWLdm2bdu3rnXqqafyzDPPUFRUxI4dO5gxYwannnpq0r/T1q1b6dw5rLb85JNP7is/66yzmDRp0r7tLVu2cNJJJzFnzhw++eQToHqmBK/XCaIm18YVkdQbPXo0+fn5ZRLEmDFjyMvL47jjjuNPf/oTPXv2rPAa1113Hdu3b+eYY47hV7/61b6aSJ8+fejXrx89e/bk0ksvLTNV+Lhx4xg6dChnnHFGmWv179+fK6+8kgEDBjBw4EDGjh1Lv379kv597rzzTi666CJOOOGEMv0bEyZMYMuWLRx77LH06dOH2bNn07FjR3Jzc7ngggvo06cPl1xySdKvU556Pd13gwah5hDPLEzeJyLJ0XTftUNVp/uu1zWIml4bV0SkNqnXCaKm18YVEalN6nWCSOfauCJ1TV1prq6r9ufvU+/HQaRrbVyRuiQrK4vNmzfTvn37cgegSfq4O5s3byYrK6tK59X7BCEiB65Lly4UFBRQWFiY7lCkHFlZWXTp0qVK5yhBiMgBa9y48b4RvFJ31Os+CBERKZ8ShIiIJKQEISIiCdWZkdRmVghUPMlK5usAbEp3EBlE70dZej9K6b0o60Dej27u3jHRjjqTIOoCM8srb8h7faT3oyy9H6X0XpSVqvdDTUwiIpKQEoSIiCSkBJFZctMdQIbR+1GW3o9Sei/KSsn7oT4IERFJSDUIERFJSAlCREQSUoLIAGZ2uJnNNrNlZrbUzG5Kd0zpZmYNzew9M/tHumNJNzNrY2ZPm9kHZrbczE5Od0zpZGa3RP9P3jezKWZWtSlKazkze9zMPjez92PK2pnZK2a2IvrZtjpeSwkiMxQDP3X3XsBJwPVm1ivNMaXbTcDydAeRIX4HvOjuPYE+1OP3xcw6AzcCOe5+LNAQGJXeqGrcH4GhcWW3ArPcvQcwK9o+YEoQGcDdN7j7u9HzbYQPgM7pjSp9zKwLcB7wWLpjSTczaw2cBvwBwN13ufuX6Y0q7RoBzcysEdAcWJ/meGqUu88BvogrHgE8GT1/EvhBdbyWEkSGMbNsoB/wdnojSasHgX8D9qY7kAzQHSgEnoia3B4zs4PSHVS6uPs64H5gLbAB2OruL6c3qoxwiLtviJ5/BhxSHRdVgsggZtYCmA7c7O5fpTuedDCzYcDn7r4w3bFkiEZAf+Bhd+8H7KCamg9qo6htfQQhcR4GHGRml6U3qsziYexCtYxfUILIEGbWmJAcJrv739MdTxoNAoab2WpgKnCmmf0lvSGlVQFQ4O4lNcqnCQmjvvoe8Im7F7r7buDvwClpjikTbDSzQwGin59Xx0WVIDKAhUV8/wAsd/cH0h1POrn7L9y9i7tnEzofX3P3evsN0d0/Az41s6OjoiHAsjSGlG5rgZPMrHn0/2YI9bjTPsZM4Iro+RXAs9VxUSWIzDAI+CHh2/Ki6HFuuoOSjDEemGxmi4G+wL1pjidtoprU08C7wBLCZ1i9mnbDzKYAbwJHm1mBmf0IuA84y8xWEGpZ91XLa2mqDRERSUQ1CBERSUgJQkREElKCEBGRhJQgREQkISUIERFJSAlCpBJmtifm9uNFZlZtI5nNLDt2Vk6RTNIo3QGI1AI73b1vuoMQqWmqQYjsJzNbbWa/NrMlZvaOmX0nKs82s9fMbLGZzTKzrlH5IWY2w8zyo0fJFBENzezRaI2Dl82sWXT8jdEaIYvNbGqafk2px5QgRCrXLK6J6ZKYfVvd/Tjgvwmz0AI8BDzp7scDk4HfR+W/B/7p7n0I8yktjcp7AJPcvTfwJXBhVH4r0C+6zrWp+uVEyqOR1CKVMLPt7t4iQflq4Ex3XxVNtviZu7c3s03Aoe6+Oyrf4O4dzKwQ6OLu38RcIxt4JVroBTP7OdDY3e8xsxeB7cAzwDPuvj3Fv6pIGapBiBwYL+d5VXwT83wPpX2D5wGTCLWNBdECOSI1RglC5MBcEvPzzej5fEqXwRwDzI2ezwKug31rbrcu76Jm1gA43N1nAz8HWgPfqsWIpJK+kYhUrpmZLYrZftHdS251bRvNsvoNMDoqG09YAe5fCavBXRWV3wTkRrNv7iEkiw0k1hD4S5REDPi9lhqVmqY+CJH9FPVB5Lj7pnTHIpIKamISEZGEVIMQEZGEVIMQEZGElCBERCQhJQgREUlICUJERBJSghARkYT+PwMoSSKCOE5ZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hbconfig import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config(\"rt-polarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Read config file name: ./config/rt-polarity\n",
       "{\n",
       "    \"data\": {\n",
       "        \"type\": \"rt-polarity\",\n",
       "        \"base_path\": \"data/\",\n",
       "        \"raw_data_path\": \"rt-polaritydata/\",\n",
       "        \"processed_path\": \"rt-polarity_processed_data\",\n",
       "        \"testset_size\": 2000,\n",
       "        \"num_classes\": 2,\n",
       "        \"PAD_ID\": 0\n",
       "    },\n",
       "    \"model\": {\n",
       "        \"batch_size\": 64,\n",
       "        \"embed_type\": \"rand\",\n",
       "        \"pretrained_embed\": \"\",\n",
       "        \"embed_dim\": 300,\n",
       "        \"num_filters\": 256,\n",
       "        \"filter_sizes\": [\n",
       "            2,\n",
       "            3,\n",
       "            4,\n",
       "            5\n",
       "        ],\n",
       "        \"dropout\": 0.5\n",
       "    },\n",
       "    \"train\": {\n",
       "        \"learning_rate\": 1e-05,\n",
       "        \"train_steps\": 20000,\n",
       "        \"model_dir\": \"logs/rt-polarity\",\n",
       "        \"save_checkpoints_steps\": 100,\n",
       "        \"loss_hook_n_iter\": 100,\n",
       "        \"check_hook_n_iter\": 100,\n",
       "        \"min_eval_frequency\": 100,\n",
       "        \"print_verbose\": true,\n",
       "        \"debug\": false\n",
       "    },\n",
       "    \"slack\": {\n",
       "        \"webhook_url\": \"\"\n",
       "    }\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
